# Talks
Contains slides from my talks.

* [HYPER: Flexible and effective pooled testing via hypergraph factorization](https://github.com/dobriban/Talks/blob/master/HYPER.pdf), Apr 2021, [Princeton IDEAS seminar]
* [What causes adversarial examples?](https://github.com/dobriban/Talks/blob/master/muri_talk.pdf), Nov 2020, [UPenn, ARO MURI reading group]
* [On the statistical foundations of adversarially robust learning](https://github.com/dobriban/Talks/blob/master/adv.pdf), Oct 2020, [Wharton, UPenn, Statistics seminar](https://statistics.wharton.upenn.edu/research/seminars-conferences/on-the-statistical-foundations-of-adversarially-robust-learning/).
* [Asymptotic perspectives on sketching](https://github.com/dobriban/Talks/blob/master/wisconsin_2020.pdf), Wisconsin [SILO 2020](https://silo.wisc.edu/).
* [Discussion on Theoretical Advances in Deep Learning](https://github.com/dobriban/Talks/blob/master/jsm_2020.pdf), JSM 2020, Discussant at [Session on Theoretical Advances in Deep Learning](https://ww2.amstat.org/meetings/jsm/2020/onlineprogram/ActivityDetails.cfm?SessionID=219277), organized by Po-Ling Loh.
* [The Implicit Regularization of Stochastic Gradient Flow for Least Squares](https://github.com/dobriban/Talks/blob/master/The%20Implicit%20Regularization%20of%20Stochastic%20Gradient%20Flow%20for%20Least%20Squares.pdf), JSM 2020.
* [Ridge Regression: Structure, Cross-Validation, and Sketching](https://github.com/dobriban/Talks/blob/master/Liu,%20Dobriban%20-%20Ridge%20Regression%20Structure,%20Cross-Validation,%20and%20Sketching.pdf), ICLR 2020.
* [Understanding Data Augmentation for Deep Learning and Beyond](https://github.com/dobriban/Talks/blob/master/aug_talk.pdf), Denver, JSM 2019.
* [A New Theory for Sketching in Linear Regression](https://github.com/dobriban/Talks/blob/master/Dobriban_-_A_new_theory_for_sketching_in_linear_regression_-_Montreal_Mar_2019.pdf), Montreal, 2019.
* [How to deal with big data? Understanding large-scale distributed regression](https://github.com/dobriban/Talks/blob/master/Dobriban_-_How_to_deal_with_big_data_-_Understanding_large-scale_distributed_regression_-_Chicago_Oct_2018.pdf), Chicago, 2018. Penn 2018.
* [Statistics, Data Science, and Machine Learning: A Very Brief Introduction](https://github.com/dobriban/Talks/blob/master/dobriban_2018_stats_ml_overview.pdf), Penn, 2018. For high school students.
* [Deterministic parallel analysis: an improved method for selecting factors and principal components](https://github.com/dobriban/Talks/blob/master/Dobriban%20-%20Deterministic%20parallel%20analysis%20for%20selecting%20the%20number%20of%20factors%20-%20France%202017.pdf), Paris, France 2017. JSM 2018, Vancouver. 
* [Optimal prediction in the linearly transformed spiked model](https://github.com/dobriban/Talks/blob/master/Dobriban%20-%20Optimal%20prediction%20in%20the%20linearly%20transformed%20spiked%20model%20-%20GATech%202017.pdf), Georgia Tech 2017, Atlanta. JSM 2017, Baltimore
* [Weighted multiple testing by convex optimization](https://github.com/dobriban/Talks/blob/master/Dobriban%20-%20Weighted%20multiple%20testing%20by%20convex%20optimization%20-%20MCP%202017%20slides.pdf),  Xth MCP 2017, Riverside
* [ ePCA. Exponential Family PCA](https://github.com/dobriban/Talks/blob/master/Dobriban%20-%20ePCA.%20Exponential%20Family%20PCA%20-%20Stanford%20Feb%202017%20-%20slides.pdf),  Stanford Statistics Seminar, Feb 2017, Stanford University
* [Computation, statistics, and random matrix theory](https://github.com/dobriban/Talks/blob/master/Dobriban%20-%20Computation,%20statistics%20and%20random%20matrix%20theory%20-%20Harvard%20Oct%202016.pdf),  Harvard Probability and Random Matrix Theory Seminar, Oct 2016, Harvard University
* [ Optimal detection of principal components in high dimensional data](https://github.com/dobriban/Talks/blob/master/Dobriban%20-%20Optimal%20detection%20of%20principal%20components%20in%20high%20dimensional%20data%20-%20Stanford%20Aug%202016%20-%20slides.pdf),  Stanford Statistics Seminar, Aug 2016, Stanford University. 3rd ISNPS conference, June 2016, Avignon. IDEAS seminar May 2016, Princeton
* [ Multiple testing with prior information identifies loci for exceptional longevity](https://github.com/dobriban/Talks/blob/master/Dobriban%20-%20Multiple%20Testing%20with%20Prior%20Information%20identifies%20loci%20for%20exceptional%20longevity%20Big%20Data%20in%20Biomedicine%202016%20poster.pdf),  poster at Big Data in Biomedicine, May 2016, Stanford 
* [High-dimensional asymptotics of prediction: ridge regression](Dobriban%20-%20High-Dimensional%20Asymptotics%20of%20Prediction.%20Ridge%20Regression%20ML%20Reading%20Gp%20Stanford%202015%20outline.pdf),  ML Reading Group, October 2015, Stanford
* [Optimal multiple testing with prior information](https://github.com/dobriban/Talks/blob/master/Dobriban%20-%20Optimal%20Multiple%20Testing%20with%20Prior%20Information%20MCP%202015%20slides.pdf),  IXth MCP 2015, Hyderabad



